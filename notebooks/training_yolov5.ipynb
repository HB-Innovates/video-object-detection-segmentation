{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install numpy torch torchvision opencv-python matplotlib scikit-learn pandas albumentations PyYAML tqdm seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training YOLOv5 for Object Detection\n",
    "\n",
    "This notebook demonstrates training a YOLOv5 model for real-time object detection on automotive video frames. It covers data loading, augmentation, model training, and evaluation. Ensure you have installed all dependencies from `requirements.txt` before running. Expected output: detection bounding boxes and mAP score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training YOLOv5\n",
    "\n",
    "This notebook is dedicated to training the YOLOv5 model on the custom automotive video dataset. It includes data loading, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.yolov5 import YOLOv5\n",
    "from src.utils import random_crop, color_jitter\n",
    "from src.evaluation import calculate_mAP\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-loading"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_dir = 'data/processed'\n",
    "train_dataset = ImageFolder(os.path.join(data_dir, 'train'), transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model-training"
   },
   "outputs": [],
   "source": [
    "# Initialize YOLOv5 model\n",
    "model = YOLOv5()\n",
    "model.load_model('path/to/yolov5_weights.pt')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for images, targets in train_loader:\n",
    "        images = images.to('cuda')\n",
    "        targets = targets.to('cuda')\n",
    "        loss = model.train_step(images, targets)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model-evaluation"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mAP = calculate_mAP(model, train_loader)\n",
    "print(f'Mean Average Precision: {mAP:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Next Steps\n",
    "\n",
    "- Review the mAP score and sample detection outputs generated.\n",
    "- For improved results, experiment with hyperparameters and data augmentation.\n",
    "- Use the trained model for inference on new video frames.\n",
    "- Document findings and share sample outputs in the project README."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
